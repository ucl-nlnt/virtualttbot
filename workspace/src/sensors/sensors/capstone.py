import rclpy
import time
import threading
import math
import cv2

from rclpy.node import Node
from nav_msgs.msg import Odometry
from sensor_msgs.msg import BatteryState
from sensor_msgs.msg import Imu
from sensor_msgs.msg import LaserScan
from rclpy.qos import qos_profile_sensor_data
from geometry_msgs.msg import Twist
import json
import argparse
from copy import deepcopy

from KNetworking import DataBridgeServer_TCP, DataBridgeClient_TCP

"""
Note that the following code was tested in a simulator and might not necessarily work on a real, physical turtlebot.
If the process requires anything GPU-related, I am 99% certain that it will not work at all.

Test system specs:
Processor: AMD Ryzen 5 5600H
RAM: 16GB LPDDR4 3200MHz (Dual-channel)
GPU: Nvidia RTX 3050ti

Edit (Nov. 24, 2023)
File has been updated to work on Turtlebot3 (MIGHT BE SLOW)
"""

import socket
import threading
import time
import sys
from collections import deque
import struct
import random
import base64

###
#   NOTE on USAGE: DataBridgeClient assumes that the Server is already running. Please ensure that it's setting up first!
###

parser = argparse.ArgumentParser(description="Turtlebot3 NLNT terminal-based client.")

parser.add_argument("--send_images", type=int, default=1, help="Enable or Disable OpenCV functions.")
parser.add_argument("--linear_x_ms", type=float, default=0.2, help="Set Turtlebot3 linear movement speed.")
parser.add_argument("--angular_z_rads", type=float, default=1.0, help="Set Turtlebot3 angular turning speed.")
parser.add_argument("--sampling_delay_t", type=float, default=0.1, help="Sets sampling frequency, hz = 1/t. NOTE: DO NOT SET LOWER THAN 0.1 SECONDS.")
parser.add_argument("--server_ip", type=str, default="None", help="Sets jump server IP address.")
parser.add_argument("--server_port", type=int, default=50000, help="Set Turtlebot server port.")
parser.add_argument("--softbarrier", type=int, default=1, help="Stops the Turtlebot a certain distance from an object in front of it. Set to 0 to disable.")
parser.add_argument("--softbarr_dist", type=float, default=0.4, help="Sets the distance at which the Turtlebot will stop with the lidar-based stop 'softbarrier.' [WARNING: Minimum value should be 0.2 meters.]")

args = parser.parse_args()
print(args)

def quaternion_to_yaw(x, y, z, w): # Generated by GPT-4
    """
    Convert a quaternion into yaw (rotation around z-axis in radians)
    """
    t3 = +2.0 * (w * z + x * y)
    t4 = +1.0 - 2.0 * (y * y + z * z)
    yaw_z = math.atan2(t3, t4)
    return yaw_z

def yaw_difference(quaternion1, quaternion2): # Generated by GPT-4
    """
    Calculate the difference in yaw between two quaternions
    """
    yaw1 = quaternion_to_yaw(*quaternion1)
    yaw2 = quaternion_to_yaw(*quaternion2)
    
    # Calculate the difference and adjust for the circular nature of angles
    difference = yaw2 - yaw1
    difference = (difference + math.pi) % (2 * math.pi) - math.pi
    
    return difference

def get_point_distance(coord_end, coord_start):

    result = 0.0

    for i in range(3):
        result += (coord_end[i] - coord_start[i]) ** 2

    return math.sqrt(result)

class SensorsSubscriber(Node):

    def __init__(self):

        super().__init__('sensors_subscriber')

        # Subscriptions
        self.create_subscription(LaserScan, 'scan', self.laserscan_callback, qos_profile_sensor_data)
        self.create_subscription(Twist,'cmd_vel', self.twist_callback, qos_profile_sensor_data)
        self.create_subscription(Imu,'imu', self.imu_callback, qos_profile_sensor_data) # IMU data doesn't seem to be useful currently // Gab
        self.create_subscription(Odometry, 'odom', self.odometer_callback, qos_profile_sensor_data)
        self.create_subscription(BatteryState, 'battery_state', self.battery_state_callback, qos_profile_sensor_data)
        self.movement_publisher = self.create_publisher(Twist, '/cmd_vel',10)
    
        # Instruction variables
        self.killswitch = False
        self.sampling_delay = args.sampling_delay_t
        self.server_ip_address = None

        # DEBUG LOCKS
        self.debug_send_data = False
        self.debug_odometer = False
        self.debug_randomizer = False
        self.debug_movement = False

        self.enable_camera = args.send_images
        self.linear_x_speed = args.linear_x_ms
        self.angular_z_speed = args.angular_z_rads
        self.destination_ip = args.server_ip
        self.camera_device = 0

        # Sensor messages:

        # laserscan
        self.laserscan_msg = None

        # twist
        self.twist_msg = None
        self.twist_timestamp = None

        # imu
        self.imu_msg = None

        # odometry
        self.odometry_msg = None
        self.odometry_msg_orientation = None
        self.odometry_msg_pos = None

        # battery
        self.battery_state_msg = None

        self.starting_odometry_set = False
        self.camera_frame_base64 = None
        
        lock = True
        while lock:

            if self.destination_ip == "None": self.destination_ip = input("Please enter the destination server's IP << ")
            try:
                self.data_transfer_client = DataBridgeClient_TCP(destination_ip_address=self.destination_ip,
                                                                destination_port=args.server_port)
                
                time.sleep(0.5) # wait for the server to open the 2nd port.
                self.movement_instruction_client = DataBridgeClient_TCP(destination_ip_address=self.destination_ip,
                                                                destination_port=args.server_port + 1)
                lock = False
            except Exception as e:
                print(e)

        # threads
        self.super_json = None
        self.is_collecting_data = False
        self.imu_timesamp = None

        # kill listener:
        self.kill_listener = threading.Thread(target=self.listen_for_shutdown)
        self.kill_listener.start()

        # Movement message server
        self.twist_msg_server_run = True
        self.twist_msg_server = threading.Thread(target=self.movement_server)
        self.twist_direction = None
        self.twist_msg_server.start()
        
        # lidar-based soft barrier
        self.barrier_thread_run = True
        if args.softbarrier:

            self.front_is_blocked = False
            self.barrier_thread = threading.Thread(target=self.soft_barrier)
            self.barrier_thread.start()
        
        # Compile Data and Transmit to Server
        self.camera_thread_run = True
        self.transmit_current_frame = False
        self.camera_thread = threading.Thread(target=self.take_photo)
        self.camera_thread.start()
        self.compilation_thread_run = True
        self.compilation_thread = threading.Thread(target = self.compile_to_json)
        self.compilation_thread.start()

        
        # Data sending to server
        self.transfer_thread_run = True
        self.transfer_thread = threading.Thread(target=self.send_to_server)
        self.transfer_thread.start()
        
        # Listen for instructions from PC/Laptop
        self.movement_subscriber_thread_run = True
        self.movement_subscriber_thread = threading.Thread(target=self.receive_movement_from_server)
        self.movement_subscriber_thread.start()
        
        print('INIT COMPLETE')

    def soft_barrier(self):

        while self.laserscan_msg == None: time.sleep(0.1) # wait for lidar scanner to wake up


        max_value = self.laserscan_msg.range_max
        min_value = self.laserscan_msg.range_min

        while self.barrier_thread_run:

            scans = deepcopy(self.laserscan_msg.ranges) # prevent race conditions
            
            # i = degree
            # val = depth or distance
            
            for i, val in enumerate(scans): # clip too small and too large values

                if (i > 30 and i < 329): 
                    continue 

                if (val < min_value and val != 0.0): 
                    scans[i] = min_value

                if (val > max_value): 
                    scans[i] = max_value

            degrees_blocked = 0
    
            for i, val in enumerate(scans):

                if (i > 30 and i < 329): 
                    continue 

                if val < args.softbarr_dist and val != 0.0:

                    degrees_blocked += 1

                    if degrees_blocked >= 5:

                        self.front_is_blocked = True
                        break # no need to iterate through other values

            if degrees_blocked < 5:
                self.front_is_blocked = False

            time.sleep(0.09) # slightly faster than nyquist frequency of lidar, which runs at a period of t = 0.2 seconds

    def listen_for_shutdown(self):

        while not self.killswitch:

            time.sleep(1)

        
        # disable all threads
        self.camera_thread_run = False
        self.compilation_thread_run = False
        self.twist_msg_server_run = False
        self.transfer_thread_run = False
        self.movement_subscriber_thread_run = False
        self.destroy_node()

        return
    
    def take_photo(self):

        try:
            
            cap = cv2.VideoCapture(self.camera_device)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH,960)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)

            print('taking a test photo...')
            ret, frame = cap.read()
            if not ret:
                self.enable_camera = False
                print('Camera is not good. Proceeding.')

        except Exception as e:

            self.enable_camera = False
            print("Error encountered when attempting to turn on camera.")

        if not self.enable_camera:
            return
        
        while self.camera_thread_run:
            
            ret, frame = cap.read()
            if not ret:
                print('WARNING: Camera failed to return an image.')
                continue

            success, encoded_image = cv2.imencode('.jpg',frame)
            if not success:
                print('WARNING: Failed to encode image.')
                continue
        
            self.camera_frame_base64 = base64.b64encode(encoded_image.tobytes()).decode('utf-8')
        
        cap.release() # close Raspi camera

        print("Camera thread closed successfully.")


    def receive_movement_from_server(self):

        while self.movement_subscriber_thread_run:

            print('waiting for inst')

            inst = self.movement_instruction_client.receive_data()

            print(f'inst: {inst}')

            if isinstance(inst, str): # see KNetworking.py for error codes.
                # TODO: implement error-handling

                print("An error has occured in the movement instruction listener client. Closing the thread. Please restart the program.")
                self.killswitch = True
                break

            elif inst == b'@0000': self.twist_direction = None
            elif inst == b'@FRWD': self.twist_direction = 'forward'
            elif inst == b'@LEFT': self.twist_direction = 'left'
            elif inst == b'@RGHT': self.twist_direction = 'right'
            elif inst == b'@STRT': 
                self.is_collecting_data = True
                print("is_collecting_data = True")
                self.starting_odometry_set = False
                time.sleep(0.2)
                self.transmit_current_frame = True # capture new latest frame
                time.sleep(0.2)
            elif inst == b'@STOP': self.is_collecting_data = False; print("is_collecting_data = False"); self.starting_odometry_set = False; self.degrees_rotated = 0; self.distance_traveled = 0; time.sleep(0.2)

            elif inst == b'@KILL': # terminate program
                self.killswitch = True
                break

            self.movement_instruction_client.send_data(b'@CONT') # give an ACK

        print('Instruction receiver thread closed successfully.')

    def send_to_server(self):

        while self.transfer_thread_run:

            if self.super_json == None or not self.is_collecting_data: time.sleep(0.1); continue; # prevent excessive CPU usage when nothing is going on
            self.data_transfer_client.send_data(str(self.super_json).encode())
            time.sleep(self.sampling_delay)

        print('Data transmission thread closed successfully.')

    def laserscan_callback(self,msg):

        self.laserscan_msg = msg

    def twist_callback(self,msg):

        # this seems redundant, but it's much easier to listen for the Twist message than to log it in the Twist server.

        if msg == None: return
        self.twist_msg = msg

    def imu_callback(self,msg):
        
        if msg == None: return
        self.imu_msg = msg
        self.imu_timesamp = time.time()

    def odometer_callback(self,msg):
        
        if msg == None: return
        
        if not self.starting_odometry_set: 
            self.starting_odometry_set = True
        
        self.odometry_msg = msg
        orientation = msg.pose.pose.orientation
        position = msg.pose.pose.position
        self.odometry_msg_orientation = (orientation.x, orientation.y, orientation.z, orientation.w)
        self.odometry_msg_pos = (position.x, position.y, position.z)


    def battery_state_callback(self,msg):

        if msg == None: return
        self.battery_state_msg = msg

    def compile_to_json(self):

        # Runs asynchronously.
        # Prevent variable was not declared errors.
        laserscan_msg_jsonized = None
        twist_msg_jsonized = {
                    "linear":(0.0, 0.0, 0.0),
                    "angular":(0.0, 0.0, 0.0),
                    "time":time.time()
                }
        
        imu_msg_jsonized = None
        odometry_msg_jsonized = None
        battery_state_msg_jsonized = None

        while self.compilation_thread_run:

            if not self.is_collecting_data: time.sleep(0.1); continue

            if self.laserscan_msg != None:

                laserscan_msg_jsonized = {
                    # "seq":self.laserscan_msg.header.seq,       # Broken. Cannot find any documentation
                    # "frame_id":self.laserscan_msg.frame_id,
                    "time_sec":self.laserscan_msg.header.stamp.sec,
                    "time_nano":self.laserscan_msg.header.stamp.nanosec,
                    "angle_min":self.laserscan_msg.angle_min,
                    "angle_max":self.laserscan_msg.angle_max,
                    "angle_increment":self.laserscan_msg.time_increment,
                    "scan_time":self.laserscan_msg.scan_time,
                    "range_min":self.laserscan_msg.range_min,
                    "range_max":self.laserscan_msg.range_max,
                    "ranges":[i for i in self.laserscan_msg.ranges],
                    "intensities":[i for i in self.laserscan_msg.intensities]
                }

            if self.twist_msg != None:

                twist_msg_jsonized = {
                    "linear":(self.twist_msg.linear.x, self.twist_msg.linear.y, self.twist_msg.linear.z),
                    "angular":(self.twist_msg.angular.x, self.twist_msg.angular.y, self.twist_msg.angular.z),
                    "time":self.twist_timestamp,
                    "is_blocked": 1 if self.front_is_blocked else 0
                }

            if self.imu_msg != None:
                
                imu_msg_jsonized = {
                    "time": self.imu_timesamp,
                    "quarternion_orientation": (self.imu_msg.orientation.x, self.imu_msg.orientation.y, self.imu_msg.orientation.z, self.imu_msg.orientation.w),
                    "orientation_covariance": [i for i in self.imu_msg.orientation_covariance],
                    "angular_velocity": (self.imu_msg.angular_velocity.x, self.imu_msg.angular_velocity.y, self.imu_msg.angular_velocity.z),
                    "angular_velocity_covariance": [i for i in self.imu_msg.angular_velocity_covariance],
                    "linear_acceleration": (self.imu_msg.linear_acceleration.x, self.imu_msg.linear_acceleration.y, self.imu_msg.linear_acceleration.z),
                    "linear_acceleration_covariance": [i for i in self.imu_msg.linear_acceleration_covariance]
                }
            
            if self.odometry_msg != None:
                
                msg_pose = self.odometry_msg.pose.pose
                position, orientation = msg_pose.position, msg_pose.orientation
                msg_pose_covariance = self.odometry_msg.pose.covariance

                odometry_msg_jsonized = {
                    "time_sec":self.odometry_msg.header.stamp.sec,
                    "time_nano":self.odometry_msg.header.stamp.nanosec,
                    "pose_position":(position.x, position.y, position.z),
                    "pose_orientation_quarternion":(orientation.x, orientation.y, orientation.z, orientation.w),
                    "object_covariance":[i for i in msg_pose_covariance]
                }

            if self.battery_state_msg != None:

                battery_state_msg_jsonized = {
                    "percentage":self.battery_state_msg.percentage,
                    "voltage":self.battery_state_msg.voltage,
                    "temperature":self.battery_state_msg.temperature,
                    "current":self.battery_state_msg.current,
                }
        
            if self.transmit_current_frame:
                
                # as of this iteration, will only send essential camera frames to make sure that file size stays low

                self.super_json = json.dumps({"laser_scan":laserscan_msg_jsonized, "twist":twist_msg_jsonized, "imu":imu_msg_jsonized, "odometry":odometry_msg_jsonized, "battery":battery_state_msg_jsonized, "frame_data":self.camera_frame_base64})
                self.transmit_current_frame = False
                print('Sent current camera image.')
            
            else:

                self.super_json = json.dumps({"laser_scan":laserscan_msg_jsonized, "twist":twist_msg_jsonized, "imu":imu_msg_jsonized, "odometry":odometry_msg_jsonized, "battery":battery_state_msg_jsonized, "frame_data":None})

            time.sleep(self.sampling_delay)
    
        print('Super BSON compilation thread closed successfully.')

    def movement_server(self):

        # Movment server keeps the last significant twist message instruction
        # meaning, the last timestamp is when the direction last changed
        
        # Slow starts stop the wheels from slipping, increasing precision of movement

        last_twist_direction = None
        data = Twist()
        while self.twist_msg_server_run: # keep thread on forever

            if self.twist_direction == None:
                time.sleep(0.05)
                continue

            # starting odometry is here to help compute the "Reactionary angular z" to help the turtlebot keep straight.
            elif self.twist_direction == 'stop':
                
                self.twist_timestamp = time.time()

                data.linear.x = 0.0
                data.angular.z = 0.0

                self.movement_publisher.publish(data)
                time.sleep(0.1)

            elif self.twist_direction == 'forward':

                if args.softbarrier:

                    if self.front_is_blocked:

                        print("Cannot move forward! Front is blocked.")
                        time.sleep(0.5)
                        continue

                # correctional mechanism to keep Turtlebot 3 moving straight
                starting_odometry = self.odometry_msg_orientation
                starting_position = self.odometry_msg_pos

                total_distance_traveled = 0.0
                self.twist_timestamp = time.time()
            
                # slow start is used to avoid jittery movements
                slow_start = 1
                P_gain = 0.1  # Proportional gain for correction; adjust as needed

                distance_lock = 0

                while self.twist_direction == 'forward':
                
                    # pass
                    yaw_diff = yaw_difference(quaternion2=self.odometry_msg_orientation, quaternion1=starting_odometry)
                    
                    if yaw_diff == 0.0:
                        print('WARN: yaw diff is zero.')

                    correctionary_angular_z = -yaw_diff / P_gain

                    # Clamp the correction to maximum limits to avoid too sharp turns
                    max_angular_z = 1.2
                    correctionary_angular_z = max(-max_angular_z, min(max_angular_z, correctionary_angular_z))

                    if slow_start < 50:

                        slow_start += 1

                    data.linear.x = self.linear_x_speed * slow_start / 50
                    data.angular.z = correctionary_angular_z
                    self.movement_publisher.publish(data)

                    if args.softbarrier:

                        if self.front_is_blocked:
                            
                            print("Cannot move forward! Front is blocked.")
                            break

                    if distance_lock == 20:

                        distance_lock = 0
                        print("[frwd] Distance from start of instruction:",round(get_point_distance(self.odometry_msg_pos, starting_position), 3))

                    distance_lock += 1
                    time.sleep(0.01)

                self.stall(0.5)

                print('[frwd] Final travel distance:', round(get_point_distance(self.odometry_msg_pos, starting_position),3))
                print('[frwd] Final yaw deviation:', round(yaw_diff * 180 / math.pi,3), 'degrees')

            elif self.twist_direction == 'left':

                self.twist_timestamp = time.time()
                data.linear.x = 0.0
                slow_start = 1

                iter_lock = 0
                total_rotation = 0.0
                last_orientation = self.odometry_msg_orientation

                while self.twist_direction == 'left':
                    
                    if slow_start != 10:
                        slow_start += 1
        
                    angular_z = slow_start/10 * self.angular_z_speed
                    data.angular.z = angular_z
                    self.movement_publisher.publish(data)

                    if iter_lock == 20:
                        
                        iter_lock = 0
                        print(f'[left] Total angular displacement: {round(total_rotation * 180 / math.pi,3)} degrees | {round(total_rotation,3)} rads')
                    
                    if not iter_lock % 5:

                        total_rotation += yaw_difference(quaternion1=last_orientation,quaternion2=self.odometry_msg_orientation)
                        last_orientation = self.odometry_msg_orientation
                        
                    iter_lock += 1
                    time.sleep(0.01)

                self.stall(0.5)

                total_rotation += yaw_difference(quaternion1=last_orientation,quaternion2=self.odometry_msg_orientation)
                print(f'[left] Final total angular displacement: {round(total_rotation * 180 / math.pi,3)} degrees | {round(total_rotation,3)} rads')

            elif self.twist_direction == 'right':

                self.twist_timestamp = time.time()
                data.linear.x = 0.0
                slow_start = 1

                iter_lock = 0
                total_rotation = 0.0
                last_orientation = self.odometry_msg_orientation

                while self.twist_direction == 'right':

                    if slow_start != 10:
                        slow_start += 1

                    angular_z = -slow_start/10 * self.angular_z_speed
                    data.angular.z = angular_z
                    
                    self.movement_publisher.publish(data)
                    if iter_lock == 20:
                        
                        iter_lock = 0
                        print(f'[rght] Total angular displacement: {round(total_rotation * 180 / math.pi,3)} degrees | {round(total_rotation,3)} rads')
                    
                    if not iter_lock % 5:

                        total_rotation += yaw_difference(quaternion1=last_orientation,quaternion2=self.odometry_msg_orientation)
                        last_orientation = self.odometry_msg_orientation
                        
                    iter_lock += 1
                    time.sleep(0.01)

                self.stall(0.5)

                total_rotation += yaw_difference(quaternion1=last_orientation,quaternion2=self.odometry_msg_orientation)
                print(f'[rght] Total angular displacement: {round(total_rotation * 180 / math.pi,3)} degrees | {round(total_rotation,3)} rads')

                

        print('Movement thread closed successfully.')

    def stall(self, stop_time=-1): 
        
        # used to simulate inference steps and to decelerate
        # the robot

        print('total time:', time.time() - self.twist_timestamp)

        self.twist_timestamp = time.time()
        data = Twist()
        data.linear.x = 0.0
        data.angular.z = 0.0
        self.movement_publisher.publish(data)
        
        time.sleep(stop_time)

        self.transmit_current_frame = True
        
        time.sleep(0.1)

        if stop_time == -1:
            return

def main(args=None):

    rclpy.init(args=args)

    try:
        sensors_subscriber = SensorsSubscriber()
        rclpy.spin(sensors_subscriber)
    finally:
        sensors_subscriber.killswitch = True
        time.sleep(3) # wait for threads to shut down.

if __name__ == '__main__':

    main()
